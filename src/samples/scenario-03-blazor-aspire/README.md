# Scenario 04 â€” Blazor + Aspire + Ollama Multi-Service Conversation

A real-time conversation app featuring **dual Blazor frontends** (voice chat + game) sharing a **single Aspire-managed API backend** with **Ollama-powered** AI, demonstrating microservice architecture with shared infrastructure.

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  .NET Aspire AppHost (scenario-04.AppHost)        â”‚
â”‚         (Orchestration Â· Discovery Â· Dashboard Â· Telemetry)       â”‚
â””â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
   â”‚                    â”‚                  â”‚                  â”‚
   â–¼                    â–¼                  â–¼                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Web Svc    â”‚  â”‚  Game Svc    â”‚  â”‚  API Backend â”‚  â”‚  Ollama  â”‚
â”‚  Blazor     â”‚  â”‚  Blazor      â”‚  â”‚ (ASP.NET     â”‚  â”‚Container â”‚
â”‚  Server     â”‚  â”‚  Server      â”‚  â”‚  Core)       â”‚  â”‚phi4-mini â”‚
â”‚             â”‚  â”‚              â”‚  â”‚              â”‚  â”‚          â”‚
â”‚ Convers.    â”‚  â”‚ Game.razor + â”‚  â”‚ ConversHub   â”‚  â”‚REST API  â”‚
â”‚ razor       â”‚  â”‚ game-engine  â”‚  â”‚ GameHub      â”‚  â”‚:11434    â”‚
â”‚ (voice)     â”‚  â”‚ .js          â”‚  â”‚ M.E.AI       â”‚  â”‚          â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
      â”‚                 â”‚                 â”‚              â”‚
      â”‚ SignalR         â”‚ SignalR         â”‚ Ollama API   â”‚
      â”‚ (discovery)     â”‚ (discovery)     â”‚ (OpenAI-compat)
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤              â”‚
                        â”‚                 â”‚              â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”˜
```

### Data Flow

```
Voice Chat (Web):              Game Commands (Game):
User speaks via mic            Player input (keyboard/mouse)
    â”‚                                â”‚
    â–¼                                â–¼
Blazor Web (SignalR)  â”      Blazor Game (SignalR)
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â–¼                       â–¼
        API Backend (scenario-04.Api)
        - ConversationHub (voice)
        - GameHub (game state)
             â”‚
             â–¼
        Ollama (phi4-mini)
             â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
    â–¼                 â–¼
Response text      Game logic feedback
    â”‚                 â”‚
Blazor Web         Blazor Game
streams audio      updates canvas
```

## Prerequisites

1. **.NET 10 SDK** (or .NET 9 SDK)
2. **Ollama** installed and running locally â€” [ollama.com](https://ollama.com)
3. **phi4-mini model** pulled: `ollama pull phi4-mini`

## How to Run

```bash
# 1. Start Ollama (if not already running):
ollama serve

# 2. Pull the model (first time only):
ollama pull phi4-mini

# 3. From the repo root:
cd src/samples/scenario-04-blazor-aspire

# 4. Run the Aspire AppHost (starts API + Web + Game):
dotnet run --project scenario-04.AppHost
```

### What happens when you run it:

1. **Aspire starts the API backend** â€” connects to Ollama at `http://localhost:11434`, exposes ConversationHub + GameHub
2. **Aspire starts the Web frontend** â€” voice chat UI, connects to API via SignalR
3. **Aspire starts the Game frontend** â€” side-scroller game, connects to API via SignalR  
4. **Aspire Dashboard opens** â€” shows all three services, logs, traces

### Using Docker-managed Ollama (optional)

If you prefer Aspire to manage Ollama via Docker instead of running it locally, edit `scenario-04.AppHost/Program.cs` and uncomment the Docker-based Ollama section. This requires Docker Desktop to be running.

## Using the App

### Web Frontend (Voice Chat)

1. Open the **Web** service endpoint from the Aspire dashboard (or the URL printed in console)
2. Navigate to `/conversation`
3. Type a message or use voice modes (see below)
4. Watch the AI response stream in real-time, token by token

### Game Frontend (Side-Scroller)

1. Open the **Game** service endpoint from the Aspire dashboard
2. Navigate to `/game`
3. Use keyboard/mouse controls to play
4. Game logic is powered by the shared API backend

### Features (Voice Chat)

- **Streaming responses** â€” tokens appear as Ollama generates them
- **Multi-turn conversation** â€” context is maintained across messages
- **Custom persona** â€” set a system prompt (e.g., "You are a pirate captain")
- **Session management** â€” clear history and start fresh
- **Connection status** â€” visual indicator for SignalR connection health
- **ğŸ—£ï¸ Speak Mode** â€” always-on microphone with automatic turn detection (GPT-Realtime-like hands-free conversation)
- **ğŸ¤ Push-to-talk** â€” single utterance voice input
- **ğŸ”Š Auto-speak** â€” AI responses spoken aloud via browser TTS

### Voice Modes

| Mode | How it works | Best for |
|------|-------------|----------|
| **Text** | Type and press Enter/Send | Normal chat |
| **Push-to-talk (ğŸ¤)** | Click mic â†’ speak â†’ auto-sends on pause | Quick voice input |
| **Speak Mode (ğŸ—£ï¸)** | Click to enter always-on mode. Mic stays open, auto-sends on each pause, AI speaks response, mic resumes listening. Click ğŸ”´ or â¹ï¸ Stop to exit. | Hands-free conversation |

In Speak Mode, the state indicator shows:
- ğŸŸ¢ **Listening** â€” mic is open, waiting for you to speak
- ğŸ¤ **Hearing you...** â€” speech detected, transcribing
- â³ **Processing** â€” sending to Ollama
- ğŸ”Š **Speaking** â€” AI is responding (interrupt by speaking again)

## Key Technology Choices

| Component | Technology | Version | Why |
|-----------|-----------|---------|-----|
| Frontend | **Blazor Server** | .NET 10 | SignalR built-in, server-side rendering |
| Communication | **SignalR + MessagePack** | 10.0.3 | Binary streaming, auto-reconnect |
| AI Framework | **Microsoft Agent Framework** | 1.0.0-rc2 | `AIAgent` + `OllamaChatClient` ([docs](https://learn.microsoft.com/agent-framework/agents/providers/ollama)) |
| AI Abstractions | **Microsoft.Extensions.AI.Ollama** | 9.7.0-preview | `OllamaChatClient` as `IChatClient` |
| LLM | **Ollama (phi4-mini)** | latest | 3.8B params, fast, runs locally |
| Orchestration | **.NET Aspire** | 13.1.2 | Service discovery, telemetry, container management |

## Microsoft Agent Framework Integration

This scenario follows the [official Microsoft Agent Framework + Ollama pattern](https://learn.microsoft.com/agent-framework/agents/providers/ollama).

### How it works

**1. Register OllamaChatClient as IChatClient (Program.cs):**

```csharp
// Microsoft.Extensions.AI.Ollama provides OllamaChatClient
builder.Services.AddChatClient(new OllamaChatClient(
        new Uri(ollamaEndpoint), ollamaModel))
    .UseFunctionInvocation()    // Enable function/tool calling
    .UseOpenTelemetry()         // Traces visible in Aspire dashboard
    .UseLogging();              // Log all AI interactions
```

**2. One-shot agent query (Agent Framework pattern):**

```csharp
using Microsoft.Agents.AI;

// Create an AIAgent from the IChatClient â€” this is the Agent Framework pattern
var agent = chatClient.AsAIAgent(
    instructions: "You are a helpful assistant running locally via Ollama.");

var result = await agent.RunAsync("What is the largest city in France?");
Console.WriteLine(result.Text);
```

**3. Multi-turn streaming conversation (ConversationService):**

```csharp
// For multi-turn chat, we manage history per session and stream tokens
await foreach (var token in chatClient.GetStreamingResponseAsync(chatHistory))
{
    yield return token.Text;  // Stream each token to the Blazor UI via SignalR
}
```

### Packages used

```xml
<PackageReference Include="Microsoft.Extensions.AI" Version="10.3.0" />
<PackageReference Include="Microsoft.Extensions.AI.Ollama" Version="9.7.0-preview.1.25356.2" />
<PackageReference Include="Microsoft.Agents.AI" Version="1.0.0-rc2" />
```

## Changing the Ollama Model

Pull a different model and update `scenario-04.Api/appsettings.json` (or set the `Ollama:Model` config):

```bash
ollama pull llama3.2
```

Then set the model name in the API config or environment variable:

```json
{
  "Ollama": {
    "Endpoint": "http://localhost:11434",
    "Model": "llama3.2"
  }
}
```

Popular options:
| Model | Size | Speed | Quality |
|-------|------|-------|---------|
| `phi4-mini` | ~2.5 GB | âš¡ Fast | Good |
| `llama3.2` | ~2 GB | âš¡ Fast | Good |
| `llama3.1:8b` | ~4.7 GB | Medium | Better |
| `phi4` | ~9 GB | Slower | Best |

## Project Structure

```
scenario-03-blazor-aspire/
â”œâ”€â”€ scenario-04.AppHost/           # Aspire orchestrator
â”‚   â””â”€â”€ Program.cs                 # Ollama + API + Web + Game wiring
â”œâ”€â”€ scenario-04.ServiceDefaults/   # Shared telemetry/health
â”‚   â””â”€â”€ Extensions.cs
â”œâ”€â”€ scenario-04.Api/               # ASP.NET Core shared backend
â”‚   â”œâ”€â”€ Program.cs                 # DI, SignalR, M.E.AI setup
â”‚   â”œâ”€â”€ Hubs/
â”‚   â”‚   â”œâ”€â”€ ConversationHub.cs     # SignalR hub (voice chat)
â”‚   â”‚   â””â”€â”€ GameHub.cs             # SignalR hub (game state)
â”‚   â””â”€â”€ Services/
â”‚       â”œâ”€â”€ ConversationService.cs # Multi-turn chat with Ollama
â”‚       â””â”€â”€ GameService.cs         # Game logic with Ollama reasoning
â”œâ”€â”€ scenario-04.Web/               # Blazor Server voice chat frontend
â”‚   â”œâ”€â”€ Program.cs
â”‚   â”œâ”€â”€ Components/
â”‚   â”‚   â”œâ”€â”€ App.razor
â”‚   â”‚   â”œâ”€â”€ Routes.razor
â”‚   â”‚   â”œâ”€â”€ Layout/MainLayout.razor
â”‚   â”‚   â””â”€â”€ Pages/
â”‚   â”‚       â”œâ”€â”€ Index.razor        # Home page
â”‚   â”‚       â””â”€â”€ Conversation.razor # Voice chat UI
â”‚   â””â”€â”€ wwwroot/css/app.css
â”œâ”€â”€ scenario-04.Game/              # Blazor Server game frontend (NEW)
â”‚   â”œâ”€â”€ Program.cs
â”‚   â”œâ”€â”€ Components/
â”‚   â”‚   â”œâ”€â”€ App.razor
â”‚   â”‚   â”œâ”€â”€ Routes.razor
â”‚   â”‚   â””â”€â”€ Pages/
â”‚   â”‚       â”œâ”€â”€ Index.razor        # Home page
â”‚   â”‚       â””â”€â”€ Game.razor         # Game UI
â”‚   â””â”€â”€ wwwroot/
â”‚       â”œâ”€â”€ css/app.css
â”‚       â””â”€â”€ js/game-engine.js      # Game canvas & input handling
â””â”€â”€ scenario-04.Shared/            # Shared DTOs across all services
    â””â”€â”€ Models/
        â”œâ”€â”€ AudioChunkDto.cs
        â”œâ”€â”€ ChatMessageDto.cs
        â”œâ”€â”€ ConversationStateDto.cs
        â”œâ”€â”€ GameStateDto.cs        # Game state (player position, enemies, etc.)
        â””â”€â”€ GameCommandDto.cs      # Game input (move, attack, etc.)
```

## Future: PersonaPlex Audio Integration

When the PersonaPlex ONNX models are fully exported, this scenario will be extended to support:

```
User speaks â†’ Mimi Encoder â†’ Ollama reasoning â†’ Mimi Decoder â†’ AI speaks back
```

The `ConversationHub.ProcessAudio()` method has a placeholder ready for this integration. See the [evaluation document](../../../docs/scenario-04-blazor-aspire-evaluation.md) for the full roadmap.

