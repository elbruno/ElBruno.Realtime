# ElBruno.Realtime â€” Project Instructions for SQUAD

## Goal

Build and evolve a **pluggable real-time audio conversation framework for .NET** that makes it trivially easy for developers to add voice conversations to their apps. Everything runs locally â€” no cloud dependencies.

A developer should be able to write:

```csharp
builder.Services.AddPersonaPlexRealtime(opts =>
{
    opts.DefaultSystemPrompt = "You are a helpful voice assistant.";
})
.UseWhisperStt()    // local speech-to-text
.UseQwenTts()       // local text-to-speech
.UseSileroVad();    // voice activity detection

builder.Services.AddChatClient(new OllamaChatClient(
    new Uri("http://localhost:11434"), "phi4-mini"));
```

...and get a complete voice conversation pipeline that handles VAD â†’ STT â†’ LLM â†’ TTS transparently.

---

## Architecture

```
    Microphone (Audio Input)
        â”‚ raw 16kHz 16-bit mono PCM
        â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Layer 3: ORCHESTRATION                           â”‚
    â”‚  IRealtimeConversationClient                      â”‚
    â”‚  RealtimeConversationPipeline                     â”‚
    â”‚  Chains all components automatically              â”‚
    â”‚  DI: builder.Services.AddPersonaPlexRealtime()    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚ uses
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Layer 2: COMPONENT ABSTRACTIONS                  â”‚
    â”‚                                                    â”‚
    â”‚  ISpeechToTextClient (M.E.AI)  â”‚ ITextToSpeechClient (ours)  â”‚
    â”‚  â”œâ”€ WhisperSpeechToTextClient  â”‚ â”œâ”€ QwenTextToSpeechClient   â”‚
    â”‚  â””â”€ (pluggable)               â”‚ â””â”€ (pluggable)              â”‚
    â”‚                                â”‚                              â”‚
    â”‚  IChatClient (M.E.AI)          â”‚ IVoiceActivityDetector (ours)â”‚
    â”‚  â”œâ”€ OllamaChatClient           â”‚ â”œâ”€ SileroVadDetector         â”‚
    â”‚  â””â”€ OpenAIChatClient           â”‚ â””â”€ (pluggable)              â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚ uses
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Layer 1: MODEL ENGINES                           â”‚
    â”‚  Whisper.net (GGML) â”‚ QwenTTS (ONNX) â”‚ Silero VAD (ONNX)    â”‚
    â”‚  ONNX Runtime       â”‚ Ollama          â”‚ Microsoft.Extensions.AI â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Flow

**One-shot turn** (`ProcessTurnAsync`):
```
Audio Stream â†’ ISpeechToTextClient.GetTextAsync() â†’ text
    â†’ IChatClient.GetResponseAsync() â†’ response text
        â†’ ITextToSpeechClient.GetSpeechAsync() â†’ ConversationTurn
```

**Streaming conversation** (`ConverseAsync`):
```
Audio Chunks â†’ IVoiceActivityDetector.DetectSpeechAsync()
    â†’ SpeechSegment â†’ ISpeechToTextClient â†’ IChatClient â†’ ITextToSpeechClient
    â†’ ConversationEvent stream (transcription, text chunks, audio chunks)
```

---

## Models Used

| Model | Package | Size | Role | Format | Auto-Download |
|-------|---------|------|------|--------|---------------|
| **Silero VAD v5** | `ElBruno.Realtime.SileroVad` | ~2 MB | Detects speech vs. silence | ONNX | âœ… from HuggingFace |
| **Whisper tiny.en** | `ElBruno.Realtime.Whisper` | ~75 MB | Speech-to-text | GGML | âœ… via Whisper.net |
| **Whisper base.en** | `ElBruno.Realtime.Whisper` | ~142 MB | Speech-to-text (accurate) | GGML | âœ… via Whisper.net |
| **QwenTTS (Qwen3-TTS)** | `ElBruno.Realtime.QwenTTS` | ~5.5 GB | Text-to-speech | ONNX | âœ… via ElBruno.QwenTTS |
| **Phi4-Mini** | User provides | ~2.7 GB | LLM chat | Ollama | âŒ Manual: `ollama pull phi4-mini` |

All auto-downloaded models cached in `%LOCALAPPDATA%/ElBruno/PersonaPlex/`.

---

## Repository Structure

```
ElBruno.Realtime/
â”œâ”€â”€ ElBruno.Realtime.slnx              # Solution file
â”œâ”€â”€ Directory.Build.props              # net8.0;net10.0, nullable, latest
â”œâ”€â”€ README.md                          # Full README with badges, quick start
â”œâ”€â”€ LICENSE                            # MIT
â”œâ”€â”€ .github/workflows/publish.yml      # NuGet publish (OIDC)
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ElBruno.Realtime/              # Core abstractions + pipeline
â”‚   â”‚   â”œâ”€â”€ Abstractions/              # Interfaces: ITextToSpeechClient, IVoiceActivityDetector,
â”‚   â”‚   â”‚                              #   IRealtimeConversationClient, ConversationEvent, etc.
â”‚   â”‚   â”œâ”€â”€ DependencyInjection/       # AddPersonaPlexRealtime() + RealtimeBuilder
â”‚   â”‚   â”œâ”€â”€ Options/                   # RealtimeOptions (STT, TTS, VAD, conversation config)
â”‚   â”‚   â””â”€â”€ Pipeline/                  # RealtimeConversationPipeline (default orchestration)
â”‚   â”‚
â”‚   â”œâ”€â”€ ElBruno.Realtime.Whisper/      # Whisper STT provider
â”‚   â”‚   â”œâ”€â”€ WhisperSpeechToTextClient  # ISpeechToTextClient implementation
â”‚   â”‚   â”œâ”€â”€ WhisperModelManager        # GGML model download/cache
â”‚   â”‚   â””â”€â”€ WhisperRealtimeBuilderExtensions  # .UseWhisperStt()
â”‚   â”‚
â”‚   â”œâ”€â”€ ElBruno.Realtime.QwenTTS/      # QwenTTS TTS provider
â”‚   â”‚   â”œâ”€â”€ QwenTextToSpeechClient     # ITextToSpeechClient implementation
â”‚   â”‚   â””â”€â”€ QwenTtsRealtimeBuilderExtensions  # .UseQwenTts()
â”‚   â”‚
â”‚   â”œâ”€â”€ ElBruno.Realtime.SileroVad/    # Silero VAD provider
â”‚   â”‚   â”œâ”€â”€ SileroVadDetector          # IVoiceActivityDetector implementation
â”‚   â”‚   â”œâ”€â”€ SileroModelManager         # ONNX model download/cache
â”‚   â”‚   â””â”€â”€ SileroVadRealtimeBuilderExtensions  # .UseSileroVad()
â”‚   â”‚
â”‚   â”œâ”€â”€ ElBruno.Realtime.Tests/        # 33 unit tests (xUnit)
â”‚   â”‚
â”‚   â””â”€â”€ samples/
â”‚       â”œâ”€â”€ scenario-01-console/       # Minimal console demo
â”‚       â”œâ”€â”€ scenario-02-api/           # ASP.NET Core API + SignalR
â”‚       â””â”€â”€ scenario-03-blazor-aspire/ # Full Blazor + .NET Aspire app
â”‚
â””â”€â”€ docs/
    â”œâ”€â”€ models-overview.md             # Detailed model documentation
    â”œâ”€â”€ realtime-architecture.md       # Architecture + M.E.AI integration
    â””â”€â”€ publishing.md                  # NuGet publishing guide
```

---

## NuGet Packages (4)

| Package | NuGet ID | Version | Dependencies |
|---------|----------|---------|--------------|
| Core | `ElBruno.Realtime` | 0.1.0-preview | M.E.AI.Abstractions 10.0.0, M.E.DI.Abstractions 9.0.* |
| Whisper STT | `ElBruno.Realtime.Whisper` | 0.1.0-preview | Core + Whisper.net 1.9.0 |
| QwenTTS | `ElBruno.Realtime.QwenTTS` | 0.1.0-preview | Core + ElBruno.QwenTTS 0.1.7-preview |
| Silero VAD | `ElBruno.Realtime.SileroVad` | 0.1.0-preview | Core + OnnxRuntime 1.24.2 + HF Downloader 0.5.0 |

Publishing: GitHub Actions â†’ OIDC â†’ NuGet.org (workflow in `.github/workflows/publish.yml`)

---

## Microsoft.Extensions.AI Integration

### Interfaces we IMPLEMENT (from M.E.AI):
- `ISpeechToTextClient` â€” Our `WhisperSpeechToTextClient` implements this experimental interface
- `IChatClient` â€” We consume any registered `IChatClient` (Ollama, OpenAI, Azure, etc.)

### Interfaces we DEFINE (following M.E.AI patterns):
- `ITextToSpeechClient` â€” No official TTS interface exists in M.E.AI yet. Ours follows the same patterns
- `IVoiceActivityDetector` â€” Audio stream â†’ speech segments
- `IRealtimeConversationClient` â€” High-level pipeline orchestration

> **Upstream proposal**: We plan to propose `ITextToSpeechClient` to [dotnet/extensions](https://github.com/dotnet/extensions) with a link to our implementation as a reference.

---

## Key Technical Decisions

1. **Namespace**: `ElBruno.Realtime` (not `ElBruno.PersonaPlex.Realtime` â€” this is model-agnostic)
2. **Multi-target**: net8.0 + net10.0
3. **`[Experimental(MEAI001)]`**: Suppressed via `<NoWarn>` â€” we depend on M.E.AI experimental `ISpeechToTextClient`
4. **Thread safety**: `SemaphoreSlim` guards lazy model initialization; `_inferenceLock` on SileroVadDetector
5. **Path traversal protection**: All model cache dirs validated with `Path.GetFullPath()` + prefix check
6. **DI lifecycle**: All providers registered as singletons via `AddSingleton<TService>(factory)`
7. **Audio format**: 16kHz, 16-bit mono PCM throughout the pipeline
8. **QwenTTS workaround**: `TtsPipeline.SynthesizeAsync()` is file-based â€” we use temp files + cleanup

---

## Current State (2026-02-27)

### âœ… Complete
- Core abstractions + pipeline orchestration
- Whisper STT provider (9 model sizes, auto-download)
- QwenTTS TTS provider (multiple voices, wraps ElBruno.QwenTTS)
- Silero VAD provider (ONNX Runtime, RNN state tracking)
- DI: `AddPersonaPlexRealtime()` with fluent builder
- 66 tests passing (33 Ã— 2 TFMs)
- 3 sample scenarios (console, API, Blazor+Aspire)
- Security hardened (path traversal, input size limits, concurrency)
- NuGet packaging + GitHub Actions publish workflow
- Documentation (README, architecture, models overview)

### ðŸ”® Future Work
- **Server-side TTS streaming**: Stream audio chunks back to browser via SignalR as they're synthesized
- **Full-duplex barge-in**: Detect user speech during AI response, cancel TTS, restart pipeline (state machine: IDLEâ†’LISTENINGâ†’PROCESSINGâ†’SPEAKINGâ†’INTERRUPTED)
- **Browser integration**: WebRTC or MediaStream API for browser microphone â†’ server pipeline
- **Additional STT providers**: Azure Speech, Google Speech, faster-whisper
- **Additional TTS providers**: Piper TTS, Azure Speech, browser SpeechSynthesis
- **Propose `ITextToSpeechClient`**: File GitHub Issue on dotnet/extensions with our implementation as reference
- **Performance**: Pipeline latency profiling, model warm-up, concurrent session support
- **CI/CD**: Add build+test workflow, code coverage, automated NuGet preview releases

---

## Related Projects

- [ElBruno.PersonaPlex](https://github.com/elbruno/ElBruno.PersonaPlex) â€” NVIDIA PersonaPlex-7B-v1 ONNX inference (the original model this was born from)
- [ElBruno.QwenTTS](https://github.com/elbruno/ElBruno.QwenTTS) â€” QwenTTS text-to-speech (used by our TTS provider)
- [ElBruno.HuggingFace.Downloader](https://github.com/elbruno/ElBruno.HuggingFace.Downloader) â€” Model downloader (used by Silero VAD provider)
- [ElBruno.VibeVoiceTTS](https://github.com/elbruno/ElBruno.VibeVoiceTTS) â€” Alternative TTS library
- [ElBruno.Text2Image](https://github.com/elbruno/ElBruno.Text2Image) â€” Text-to-image generation

---

## Team Roles Needed

| Role | Responsibility |
|------|---------------|
| **Architect** | Pipeline design, M.E.AI alignment, interface evolution |
| **C# Developer** | Provider implementations, DI extensions, streaming patterns |
| **ML/ONNX Specialist** | Model loading, tensor formats, inference optimization, new model providers |
| **Frontend Developer** | Blazor UI, browser audio integration, WebRTC/MediaStream |
| **Security Reviewer** | Audio data privacy, model download verification, input validation |
| **DevOps** | CI/CD, NuGet publishing, version management |
| **Documentation** | API docs, samples, migration guides |
